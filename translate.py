import os
import re
import sys
import time
from google import genai
from google.genai import types
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
from dotenv import load_dotenv
load_dotenv()

# ================= Config =================
API_KEY = os.getenv("GEMINI_API_KEY")

POSTS_DIR = "source/_posts"

MAX_WORKERS = 1

MODEL_NAME = "gemini-2.5-pro"
# ===========================================

if not API_KEY:
    print("[ERROR] GEMINI_API_KEY environment variable not set.")
    sys.exit(1)

client = genai.Client(api_key=API_KEY)

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ 22/7 (ãƒŠãƒŠãƒ‹ã‚¸) çš„èµ„æ·±ç²‰ä¸å…¼å­—å¹•ç»„ç¿»è¯‘ã€‚
ä»»åŠ¡ï¼šå°† HTML/Markdown åšå®¢ä»æ—¥è¯­ç¿»è¯‘æˆä¸­æ–‡ã€‚

**è¾“å‡ºé™åˆ¶ï¼ˆè‡³å…³é‡è¦ï¼‰**ï¼š
1.  **åªè¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹**ã€‚
2.  **ç»å¯¹ä¸è¦**è¾“å‡ºæ—¥è¯­åŸæ–‡ï¼(åŸæ–‡ç”±å¤–éƒ¨ç¨‹åºä¿ç•™)
3.  **ä¸è¦**åŒ…å« Markdown ä»£ç å—æ ‡è®° (å¦‚ ```html)ã€‚

**å›¾ç‰‡å¤„ç†è§„åˆ™**ï¼š
- å½“ä½ åœ¨æ–‡ä¸­é‡åˆ° `<img>` æ ‡ç­¾æˆ– `![alt](url)` æ—¶ï¼š
- **ä¸è¦**ä¿ç•™åŸå›¾ç‰‡é“¾æ¥ï¼ˆé“¾æ¥å·²åœ¨åŸæ–‡ä¸­ä¿å­˜ï¼‰ã€‚
- **å¿…é¡»**åœ¨å¯¹åº”ä½ç½®è¾“å‡ºä¸€ä¸ªå ä½ç¬¦ï¼š
  `<div class="nananiji-img-placeholder"></div>`

**ã€æˆå‘˜å…³ç³»ä¸ç§°å‘¼è§„èŒƒã€‘**
1. **å‰è¾ˆ**ï¼š
   - **ã‚µãƒªãƒ¼** -> **èè‰** (æ— å°å§ï¼Œæ—  English)ã€‚
   - å¦‚æœå‡ºç°äº†ã•ã‚“å°±åŠ ä¸Šå‰è¾ˆ
   - æ— æ³•åˆ¤æ–­æ˜¯å‰è¾ˆè¿˜æ˜¯åè¾ˆå°±å»æ‰ `ã•ã‚“`ï¼Œç›´å‘¼å…¶åæˆ–åŠ é…±ã€‚
2. **åŒæœŸ/åè¾ˆ**ï¼š
   - å»æ‰ `ã•ã‚“`ï¼Œç›´å‘¼å…¶åæˆ–åŠ é…±ã€‚
   - **æœ›æœˆã‚Šã®** -> **ã‚Šã®** (ä¿ç•™åŸå)ã€‚
3. **å¤–éƒ¨äººå‘˜**ï¼š
   - å‡ååå­—**ä¿ç•™åŸæ–‡**ã€‚
4. **æ˜µç§°**ï¼š
    - æ— æ³•ç¡®å®šçš„æ˜µç§°è¯·ä¿ç•™åŸæ–‡æˆ–ä½¿ç”¨åŸåä»£æ›¿ã€‚
    - ã‚Œã„ã«ã‚ƒã‚“ -> ç²å–µ
    - ã¾ã«ã‚ƒã‚“ã€€-> èŒ‰å–µ

**è¯­æ°”é£æ ¼**ï¼š
   - ä¿æŒâ€œå¶åƒè¯­æ°”â€ï¼šå…ƒæ°”ã€å¯çˆ±ã€äº²åˆ‡ã€å¸¦ä¸€ç‚¹å°‘å¥³çš„ç¢ç¢å¿µæ„Ÿã€‚
   - æ‹’ç»â€œæœºç¿»å‘³â€ï¼šä¸è¦ç”¨å…¬æ–‡å†™ä½œçš„è¯­æ°”ï¼Œè¦åƒæ˜¯åœ¨å†™ç²‰ä¸ä¿¡ã€‚
   - ç¬¬ä¸€äººç§°ï¼šå¦‚æœåŸæ–‡è‡ªç§°â€œç§(watashi)â€æˆ–â€œåå­—â€ï¼Œé€šé¡ºæƒ…å†µä¸‹è¯‘ä¸ºâ€œæˆ‘â€ã€‚å¦‚æœåŸæ–‡æ˜¯ä¸ºäº†å–èŒæ•…æ„ç”¨ç¬¬ä¸‰äººç§°ï¼ˆå¦‚â€œæ¨±æœˆè§‰å¾—...â€ï¼‰ï¼Œåˆ™ä¿ç•™ç¬¬ä¸‰äººç§°ã€‚
   - ã‚¢ãƒ‹ãƒ© -> å‘¨å¹´ Live
   - ãƒªãƒªã‚¤ãƒ™ -> å‘å”®çºªå¿µæ´»åŠ¨
   - ç‰¹å…¸ä¼š -> ç‰¹å…¸ä¼š 
   
**ã€çº¢çº¿è§„åˆ™ã€‘**
1. **ä¸¥ç¦æ³¨éŸ³/è‹±æ–‡** (å¦‚: æ¨±æœˆ(Satsuki) -> âŒ)ã€‚
2. å¯¹äºæˆå‘˜ä¹‹é—´çš„ç§°å‘¼**ä¸¥ç¦â€œå°å§/å¥³å£«â€**ï¼Œå¯¹äºå›¢å¤–çš„å˜‰å®¾ç­‰å‡ºç°çš„äººç‰©ï¼Œå‡ºäºå°Šé‡éœ€è¦ä½¿ç”¨æ­¤ç±»å°Šç§°ï¼Œä½†æ˜¯æˆå‘˜ä¹‹é—´ä¸¥ç¦ä½¿ç”¨ã€‚
3. **é¢œæ–‡å­—/Emoji ä¿æŠ¤**ï¼š
   - ç»å¯¹ä¸è¦åˆ é™¤æˆ–â€œç¿»è¯‘â€é¢œæ–‡å­—ï¼ˆå¦‚ `( Ë™ê’³â€‹Ë™ )`ã€`(*>_<*)ï¾‰`ï¼‰ã€‚
   - ç»å¯¹ä¿ç•™æ‰€æœ‰ Emojiï¼ˆâœ¨ã€ğŸ¥ºã€ğŸŠï¼‰ã€‚
   - ä¸è¦è¯•å›¾ä¿®å¤é¢œæ–‡å­—ä¸­çš„æ ‡ç‚¹ç¬¦å·ã€‚

ğŸ“„ **ã€è¾“å‡ºæ ¼å¼ã€‘**
- ç»å¯¹ä¿ç•™ `<br>` æ¢è¡Œç¬¦ã€‚
- åªè¾“å‡ºç¿»è¯‘åçš„å†…å®¹ï¼Œä¸è¦è¾“å‡º Markdown ä»£ç å—æ ‡è®°ã€‚
"""

def split_frontmatter(content):
    match = re.match(r'^\s*(-{3,}\s*\n.*?\n-{3,}\s*\n)(.*)$', content, re.DOTALL)
    if match:
        return match.group(1), match.group(2)
    return "", content

def check_is_translated(fm_content):
    if re.search(r'^translated:\s*true', fm_content, re.MULTILINE):
        return True
    return False

def add_translated_tag(fm_content):
    if re.search(r'^translated:', fm_content, re.MULTILINE):
        return re.sub(r'^translated:.*$', 'translated: true', fm_content, flags=re.MULTILINE)
    pattern = r'(-{3,}\s*)$'
    if re.search(pattern, fm_content.strip()):
        return re.sub(pattern, r'translated: true\n\1', fm_content.strip())
    else:
        return fm_content.strip() + "\ntranslated: true\n"

def process_single_file(filepath):
    filename = os.path.basename(filepath)
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            full_content = f.read()

        fm_chunk, body_chunk = split_frontmatter(full_content)
        
        if check_is_translated(fm_chunk):
            return None 

        if 'article-translated-cn' in body_chunk:
             new_fm = add_translated_tag(fm_chunk)
             with open(filepath, 'w', encoding='utf-8') as f:
                 f.write(new_fm + "\n" + body_chunk)
             return f"[FIX] Added missing metadata tag: {filename}"

        if len(body_chunk) < 10:
             return f"[SKIP] Too short: {filename}"

        # === AI ç¿»è¯‘ ===
        max_retries = 5 
        content_cn = ""
        
        for attempt in range(max_retries):
            try:
                response = client.models.generate_content(
                    model=MODEL_NAME, 
                    contents=f"{SYSTEM_PROMPT}\n\n=== å¾…ç¿»è¯‘åŸæ–‡ ===\n{body_chunk}",
                    config=types.GenerateContentConfig(
                        safety_settings=[
                            types.SafetySetting(
                                category="HARM_CATEGORY_HATE_SPEECH",
                                threshold="BLOCK_NONE"
                            ),
                            types.SafetySetting(
                                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                                threshold="BLOCK_NONE"
                            ),
                            types.SafetySetting(
                                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                                threshold="BLOCK_NONE"
                            ),
                            types.SafetySetting(
                                category="HARM_CATEGORY_HARASSMENT",
                                threshold="BLOCK_NONE"
                            ),
                        ]
                    )
                )
                if response.text:
                    content_cn = response.text.strip()
                    break # æˆåŠŸæ‹¿åˆ°å†…å®¹ï¼Œè·³å‡ºå¾ªç¯
            except Exception as api_error:
                error_str = str(api_error)
                if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                    wait_time = 30 
                    print(f"â³ [RATE LIMIT] Sleeping 30s for {filename}...")
                    time.sleep(wait_time)
                else:
                    if attempt == max_retries - 1:
                        print(f" API Error on {filename}: {api_error}")
                    time.sleep(2)

        if not content_cn:

            return f"[ABORT] Blocked or Failed. Leaving unchanged: {filename}"

        # === åªæœ‰æˆåŠŸç¿»è¯‘åï¼Œæ‰æ‰§è¡Œä¸‹é¢çš„ä»£ç  ===
        
        content_cn = re.sub(r'^```(html|markdown)?\s*', '', content_cn)
        content_cn = re.sub(r'\s*```$', '', content_cn)

        # ç»„è£…
        new_fm = add_translated_tag(fm_chunk)
        
        final_output = f"""{new_fm}
<div class="article-content-container">
    <div class="article-original-jp">
{body_chunk}
    </div>
    <div class="article-translated-cn" style="display:none;">
{{% raw %}}
{content_cn}
{{% endraw %}}
    </div>
</div>
"""

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(final_output)
            
        time.sleep(2) 

        return None

    except Exception as e:
        return f"[ERROR] {filename}: {str(e)}"

def main():
    if not os.path.exists(POSTS_DIR):
        print(f"[ERROR] Path not found: {POSTS_DIR}")
        sys.exit(1)

    all_files = [os.path.join(POSTS_DIR, f) for f in os.listdir(POSTS_DIR) if f.endswith('.md')]
    all_files.sort(reverse=True) 

    print(f"[INFO] Scanning {len(all_files)} files...")

    pending_files = []
    
    for filepath in all_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                head_sample = f.read(1000) 
            
            match = re.match(r'^\s*(-{3,}\s*\n.*?\n-{3,}\s*\n)', head_sample, re.DOTALL)
            if match:
                fm_only = match.group(1)
                if check_is_translated(fm_only):
                    continue 
            
            pending_files.append(filepath)

        except Exception as e:
            print(f"[WARN] Cannot read {filepath}, skipping.")

    if not pending_files:
        print("[INFO] No new files to translate.")
        return

    print(f"[INFO] Processing {len(pending_files)} files...")
    print(f"[INFO] Running safely with {MAX_WORKERS} thread(s).")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = list(tqdm(executor.map(process_single_file, pending_files), total=len(pending_files), unit="files"))

    logs = [r for r in results if r is not None]
    if logs:
        print("\n" + "="*30)
        for log in logs:
            print(log)
        print("="*30)
    else:
        print("\nğŸ‰ All Done!")

if __name__ == "__main__":
    main()